{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### summary: TOP SCORES: \n",
    "#52.5% with gaussian naive bayes\n",
    "#52.5% with k-nn with ~200 neighbors\n",
    "#52.5% with logistic regression and C~1e-2\n",
    "#52% with a 2 depth decision tree\n",
    "#always going for 1 -> 51%\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "matplotlib.style.use('ggplot')\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          f1         f2         f3         f4         f5         f6  \\\n",
      "0  134182390   97300587  135824563   90767607   87687197   65148427   \n",
      "1   76630357  132348601   78121737  102794263  120848626  128752983   \n",
      "2  111610401  132186734   83887688  120772423  133722193  100560251   \n",
      "3   72896251  113365043   72912608  126007508  127949612   74975809   \n",
      "4  113253706   96665624   89391907   77862818   91855586  100094204   \n",
      "\n",
      "          f7         f8         f9        f10        f11        f12  \\\n",
      "0  109834029  131613166  135533479   92106582   98111205   87052852   \n",
      "1   71827456   95945691   98115812  135285479  137364637  130062214   \n",
      "2   69916843  100459177   80742177  134884316  129775817  131335813   \n",
      "3   87833921   68438705   76021871  116126096  118784024  112328751   \n",
      "4  116150057  114434231   98567673   86510339   81789481   87618174   \n",
      "\n",
      "         f13        f14     c1  validation  target  \n",
      "0   66216076  121781929  c1_23           0       1  \n",
      "1  114819524   76635306   c1_3           1       1  \n",
      "2   89200467   77712207  c1_20           0       0  \n",
      "3   83538128   92643596   c1_3           0       1  \n",
      "4   95158324  124902005   c1_5           0       0  \n",
      "\n",
      "\n",
      "\n",
      "Size of datasets: total - 55038, train - 44030, test - 11008, intersect: 0\n"
     ]
    }
   ],
   "source": [
    "numerai_data = pd.read_csv(\"../numerai_datasets/numerai_training_data.csv\")\n",
    "print numerai_data.head(5)\n",
    "\n",
    "#separating train and test\n",
    "frac_for_training = 0.80\n",
    "training_data = numerai_data.sample(frac=frac_for_training)\n",
    "validation_data = numerai_data.drop(training_data.index)\n",
    "check = pd.merge(training_data, validation_data, how='inner')\n",
    "\n",
    "training_data.drop('validation', axis=1, inplace=True)\n",
    "validation_data.drop('validation', axis=1, inplace=True)\n",
    "\n",
    "print('\\n\\n\\nSize of datasets: total - %s, train - %s, test - %s, intersect: %s' %(\n",
    "        numerai_data.shape[0], training_data.shape[0], validation_data.shape[0], check.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Categorical feature transformed:\n",
      "          c1  c1_int\n",
      "2840    c1_3       3\n",
      "2967    c1_3       3\n",
      "41847   c1_5       5\n",
      "39617  c1_14      14\n",
      "28299   c1_3       3\n",
      "\n",
      "\n",
      "\n",
      "Features are: f1,f2,f3,f4,f5,f6,f7,f8,f9,c1_int,f12,f13,f10,f11,f14\n"
     ]
    }
   ],
   "source": [
    "#preprocessing the categorical feature c1\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "try:\n",
    "    training_data[\"c1_int\"] = training_data[\"c1\"].apply(lambda x: int(x[3:]))\n",
    "except Exception:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit_transform(list(set(training_data[\"c1\"])))\n",
    "    training_data[\"c1_int\"] = le.transform(np.asarray(training_data[\"c1\"]))\n",
    "\n",
    "print \"Categorical feature transformed:\"\n",
    "print training_data[[\"c1\", \"c1_int\"]].head(5)\n",
    "\n",
    "#features:\n",
    "features = list(set(training_data.columns).difference({'target', 'validation','c1'}))\n",
    "print (\"\\n\\n\\nFeatures are: %s\" %','.join(features))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
